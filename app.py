import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
import os
from dotenv import load_dotenv
from pathlib import Path

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
# app.pyã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
env_path = Path(__file__).parent / '.env'
# .envãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯èª­ã¿è¾¼ã‚€
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
else:
    # .envãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å ´æ‰€ã‚’è©¦ã™
    load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# OpenAI APIã‚­ãƒ¼ã®å–å¾—é–¢æ•°
def get_api_key():
    """Streamlit Cloudã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—"""
    api_key = None
    
    # Streamlit Cloudã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
    try:
        if hasattr(st, 'secrets'):
            # Streamlit Cloudã®Secretsã¯è¾æ›¸ã®ã‚ˆã†ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            # ã¾ãšã€ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã‚’è©¦ã¿ã‚‹
            try:
                api_key = st.secrets["OPENAI_API_KEY"]
            except (KeyError, TypeError):
                # è¾æ›¸å½¢å¼ã§ãªã„å ´åˆã€getãƒ¡ã‚½ãƒƒãƒ‰ã‚’è©¦ã™
                try:
                    api_key = st.secrets.get("OPENAI_API_KEY")
                except (AttributeError, TypeError):
                    pass
    except Exception:
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ç„¡è¦–ã—ã¦æ¬¡ã¸
        pass
    
    # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãŒãªã„å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    if not api_key:
        api_key = os.getenv('OPENAI_API_KEY')
    
    return api_key

# APIã‚­ãƒ¼ã®å–å¾—
api_key = get_api_key()

# APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®å‡¦ç†
if not api_key:
    st.error("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.info("""
    **APIã‚­ãƒ¼ã®è¨­å®šæ–¹æ³•ï¼š**
    
    **ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã®å ´åˆï¼ˆæ¨å¥¨ï¼‰ï¼š**
    
    1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¼ˆ`app.py`ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ã«`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    2. ä»¥ä¸‹ã®å½¢å¼ã§ã”è‡ªèº«ã®OpenAI APIã‚­ãƒ¼ã‚’è¨˜è¿°ï¼š
       ```
       OPENAI_API_KEY=ã”è‡ªèº«ã®OpenAI APIã‚­ãƒ¼
       ```
    3. æ–‡å­—åˆ—ã‚’ã‚¯ã‚©ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§å›²ã‚€å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“
    4. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¦ã€ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„
    
    **Streamlit Cloudã®å ´åˆï¼š**
    
    1. https://share.streamlit.io/ ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³
    2. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã‚¢ãƒ—ãƒªã‚’é¸æŠ
    3. ã€ŒManage appã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. ã€ŒSecretsã€ã‚¿ãƒ–ï¼ˆã¾ãŸã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ã‚’ã‚¯ãƒªãƒƒã‚¯
    5. ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å½¢å¼ã§**æ­£ç¢ºã«**å…¥åŠ›ï¼š
       ```toml
       OPENAI_API_KEY = "sk-ã‚ãªãŸã®å®Ÿéš›ã®APIã‚­ãƒ¼"
       ```
       ã¾ãŸã¯
       ```
       OPENAI_API_KEY=sk-ã‚ãªãŸã®å®Ÿéš›ã®APIã‚­ãƒ¼
       ```
    6. **å¿…ãšã€ŒSaveã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯**ã—ã¦ä¿å­˜ï¼ˆé‡è¦ï¼ï¼‰
    7. ä¿å­˜å¾Œã€ã‚¢ãƒ—ãƒªãŒè‡ªå‹•çš„ã«å†ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¾ã™ï¼ˆé€šå¸¸10-30ç§’ï¼‰
    8. å†ãƒ‡ãƒ—ãƒ­ã‚¤ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…ã£ã¦ã‹ã‚‰ã€ã“ã®ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
    
    **ã‚ˆãã‚ã‚‹é–“é•ã„ï¼š**
    - Secretsã‚’å…¥åŠ›ã—ãŸãŒã€ä¿å­˜ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã„ãªã„
    - å¼•ç”¨ç¬¦ã®ç¨®é¡ãŒé–“é•ã£ã¦ã„ã‚‹ï¼ˆ`'`ã§ã¯ãªã`"`ã‚’ä½¿ç”¨ï¼‰
    - ä½™åˆ†ãªã‚¹ãƒšãƒ¼ã‚¹ã‚„æ”¹è¡ŒãŒå…¥ã£ã¦ã„ã‚‹
    - å†ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’å¾…ãŸãšã«ç¢ºèªã—ã¦ã„ã‚‹
    
    **è©³ç´°ãªæ‰‹é †ã¯ [`SETUP.md`](SETUP.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚**
    """)
    st.stop()

# LangChain ChatOpenAIã®åˆæœŸåŒ–
def get_chat_model():
    """LangChain ChatOpenAIãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
    if not api_key:
        return None
    try:
        return ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            max_tokens=500,
            api_key=api_key
        )
    except Exception as e:
        st.error(f"ChatOpenAIãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        st.warning("""
        **ã“ã®ã‚¨ãƒ©ãƒ¼ã¯ä¾å­˜é–¢ä¿‚ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã®å•é¡Œã§ã™ã€‚**
        
        **è§£æ±ºæ–¹æ³•ï¼š**
        1. `requirements.txt`ã‚’æ›´æ–°ã—ã¦ã€GitHubã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦ãã ã•ã„
        2. Streamlit Cloudã§ã‚¢ãƒ—ãƒªãŒè‡ªå‹•çš„ã«å†ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ã¾ã§å¾…ã£ã¦ãã ã•ã„ï¼ˆé€šå¸¸1-2åˆ†ï¼‰
        3. å†ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã€ã“ã®ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
        
        **ç¢ºèªäº‹é …ï¼š**
        - `langchain-openai>=0.1.0`ãŒ`requirements.txt`ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹
        - `langchain-core>=0.1.0`ãŒ`requirements.txt`ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹
        - å¤‰æ›´ã‚’GitHubã«ãƒ—ãƒƒã‚·ãƒ¥ã—ãŸã‹
        """)
        return None

chat_model = get_chat_model()
if chat_model is None:
    st.stop()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "expert_type" not in st.session_state:
    st.session_state.expert_type = "æ³•å‹™"

# å°‚é–€å®¶ã®ç¨®é¡ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
EXPERT_SYSTEM_MESSAGES = {
    "æ³•å‹™": "ã‚ãªãŸã¯ã€Œç¤¾å†…æ³•å‹™ãƒ˜ãƒ«ãƒ—ãƒ‡ã‚¹ã‚¯ä¸€æ¬¡å—ä»˜ãƒœãƒƒãƒˆã€ã§ã™ã€‚ç›®çš„ã¯ã€ç¤¾å†…ãƒ¡ãƒ³ãƒãƒ¼ã®è‡ªå·±è§£æ±ºã‚’ä¿ƒã—ã€æ³•å‹™éƒ¨ã¸ã®å•ã„åˆã‚ã›ä»¶æ•°ã‚’æ¸›ã‚‰ã™ã“ã¨ã§ã™ã€‚",
    "å–¶æ¥­": "ã‚ãªãŸã¯ã€Œç¤¾å†…å–¶æ¥­ãƒ˜ãƒ«ãƒ—ãƒ‡ã‚¹ã‚¯ä¸€æ¬¡å—ä»˜ãƒœãƒƒãƒˆã€ã§ã™ã€‚ç›®çš„ã¯ã€ç¤¾å†…ãƒ¡ãƒ³ãƒãƒ¼ã®è‡ªå·±è§£æ±ºã‚’ä¿ƒã—ã€å–¶æ¥­éƒ¨ã¸ã®å•ã„åˆã‚ã›ä»¶æ•°ã‚’æ¸›ã‚‰ã™ã“ã¨ã§ã™ã€‚"
}

def generate_response(user_input: str, expert_type: str, messages: list, chat_model: ChatOpenAI) -> str:
    """
    å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    
    Args:
        user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        expert_type: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã‚¿ã‚¤ãƒ—ï¼ˆ"æ³•å‹™"ã¾ãŸã¯"å–¶æ¥­"ï¼‰
        messages: ä¼šè©±å±¥æ­´ã®ãƒªã‚¹ãƒˆï¼ˆè¾æ›¸å½¢å¼: {"role": "user"/"assistant", "content": "..."}ï¼‰
        chat_model: LangChainã®ChatOpenAIãƒ¢ãƒ‡ãƒ«
    
    Returns:
        str: AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
    
    Raises:
        Exception: APIå‘¼ã³å‡ºã—æ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
    """
    # é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
    system_message_content = EXPERT_SYSTEM_MESSAGES.get(
        expert_type,
        "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    )
    
    # ChatPromptTemplateã‚’ä½œæˆ
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_message_content),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}")
    ])
    
    # ä¼šè©±å±¥æ­´ã‚’LangChainã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›ï¼ˆæœ€æ–°10ä»¶ã¾ã§ï¼‰
    chat_history = []
    for msg in messages[-10:-1]:  # æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é™¤ã
        if msg["role"] == "user":
            chat_history.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            chat_history.append(AIMessage(content=msg["content"]))
    
    # Chainã‚’ä½œæˆã—ã¦å®Ÿè¡Œ
    chain = prompt_template | chat_model
    
    # å¿œç­”ã‚’ç”Ÿæˆ
    response = chain.invoke({
        "chat_history": chat_history,
        "input": user_input
    })
    
    return response.content

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # å°‚é–€å®¶ã®é¸æŠ
    st.subheader("ğŸ‘¤ å°‚é–€å®¶ã®é¸æŠ")
    expert_type = st.radio(
        "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
        options=["æ³•å‹™", "å–¶æ¥­"],
        index=0 if st.session_state.expert_type == "æ³•å‹™" else 1,
        key="expert_radio"
    )
    
    # å°‚é–€å®¶ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
    if expert_type != st.session_state.expert_type:
        st.session_state.expert_type = expert_type
        st.info(f"å°‚é–€å®¶ã‚’ã€Œ{expert_type}ã€ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")
    
    st.markdown("---")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ã‚¯ãƒªã‚¢
    if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.info("""
    **ä½¿ã„æ–¹ï¼š**
    1. ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›
    2. Enterã‚­ãƒ¼ã‚’æŠ¼ã™ã‹é€ä¿¡ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    3. AIã‹ã‚‰ã®è¿”ä¿¡ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    
    **æ³¨æ„ï¼š**
    - OpenAI APIã®ä½¿ç”¨ã«ã¯æ–™é‡‘ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
    - ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¯æœ€æ–°10ä»¶ã¾ã§ä¿æŒã•ã‚Œã¾ã™
    """)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if user_input := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # AIå¿œç­”ã‚’ç”Ÿæˆ
    with st.chat_message("assistant"):
        with st.spinner("è€ƒãˆä¸­..."):
            try:
                # é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
                ai_response = generate_response(
                    user_input=user_input,
                    expert_type=st.session_state.expert_type,
                    messages=st.session_state.messages,
                    chat_model=chat_model
                )
                st.markdown(ai_response)
                
                # AIå¿œç­”ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«è¿½åŠ 
                st.session_state.messages.append({"role": "assistant", "content": ai_response})
                
            except Exception as e:
                error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                st.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
